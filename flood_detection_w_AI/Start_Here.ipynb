{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b5ae9e-4baf-4585-a557-3f0c7e9e7010",
   "metadata": {},
   "source": [
    "# Flood Detection Challenge\n",
    "\n",
    "This repository contains code for our submission to the **ETCI 2021 Competition on Flood Detection** ([Leaderboard](https://competitions.codalab.org/competitions/30440), [Homepage](https://nasa-impact.github.io/etci2021/)) (Winning\n",
    "Solution #2). \n",
    "\n",
    "Accompanying paper: [Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised Learning](http://arxiv.org/abs/2107.08369).\n",
    "\n",
    "by Sayak Paul\\*, Siddha Ganju\\*.\n",
    "\n",
    "(\\*) equal contribution.\n",
    "\n",
    "<div align=\"center\">\n",
    "\t<img src=\"https://i.ibb.co/X7chPyT/pipeline.png\" width=600/>\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73163af3-c457-4211-a692-507493b282db",
   "metadata": {},
   "source": [
    "## Team \n",
    "\n",
    "* [Siddha Ganju](http://sidgan.github.io/siddhaganju)\n",
    "* [Sayak Paul](https://sayak.dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fc824-53a4-4423-8391-05ddb0de5d56",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec762d-8504-40a8-b5e0-0f92b25deaac",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Unzip the data to working directory. \n",
    "<br>\n",
    "**Note**: We're working with a large data set. It could take ~40 mins to unzip all files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6282f92-feb1-4ec3-b5b3-ccc8d3da0310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -qq data/train.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140032d-0fad-4648-af50-460351d35b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq data/test.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f9039-f0d7-465e-9576-94c443d9db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq data/test_internal.zip -d ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a98a8af-ec9f-4a69-b7b4-c03878764561",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Data exploration is available in `notebooks/Data_Viz.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb27775-2874-4c04-8dc2-fd4cf7a98755",
   "metadata": {},
   "source": [
    "Link to the notebook is [**here**](Data_Viz.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6781668-ae4b-429e-8afa-50c6cf2531e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training and Submission\n",
    "\n",
    "_**⚠️ &nbsp;&nbsp; Make sure the data is downloaded and is placed in the right paths as specified in\n",
    "`src/config.py`.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08b5c7-0d7a-4f17-b159-b46373890e99",
   "metadata": {},
   "source": [
    "1. `train.py`: First, we train two models on the training set: UNet [1] and UNet++ [2] with a MobileNetV2 [3] backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba2740-b666-46bd-b0e9-b63d43fe82cb",
   "metadata": {},
   "source": [
    "**Note**: The training process takes a significant amount of time, for the sake of brevity. We're provided you an exemplary trained weights in the `Best_IoU` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87063b0d-cd83-489d-a91f-edc8b5cb0759",
   "metadata": {},
   "source": [
    "PyTorch enables multiprocessing, but we should increase the shared memory (shm) with the below command to make sure it's not limited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6165e6-bc60-47e2-aaa0-4a429b359e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mount -o remount,size=16G /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ae769-aa9d-4ed1-8ffb-1c74d3beb89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training process could take up to 1.5 hours\n",
    "# This will generate supervised_training.log and unet_mobilenet_v2_{rank}.pth\n",
    "%run src/train_unet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24b578-d891-4163-bddd-6f50bfc4d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training process could take up to 1.5 hours\n",
    "# This will generate supervised_training.log and upp_mobilenet_v2_{rank}.pth\n",
    "%run src/train_upp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8737b-b27a-45b6-b9a9-613b2c68d142",
   "metadata": {},
   "source": [
    "**Hint**: Did you get the below error message? Please restart the kernel. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "850ea83a-451b-4caf-88d6-ce6d7f045844",
   "metadata": {},
   "source": [
    "AttributeError: module '__main__' has no attribute '__spec__'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e219b-f735-455b-a1ea-7d5048036925",
   "metadata": {},
   "source": [
    "2. `notebooks/Generate_Pseudo.ipynb`:\n",
    "    * We then use their averaged ensemble to generate pseudo-labels on the unlabeled test set.\n",
    "    * We then create a new training set with these generated pseudo-labels and the existing training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7ff725-d7f4-4c56-bf30-82607692738c",
   "metadata": {},
   "source": [
    "Link to the notebook is [**here**](Generate_Pseudo.ipynb). The execution of this notebook will generate a `pseudo_labels` directory, `test_sentinel.csv`, and `pseudo_df.csv`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4078f6-3a34-4333-935a-5e3e8be2d65f",
   "metadata": {},
   "source": [
    "3. `train_pseudo_label.py`: We fine-tune the **UNet model weights** obtained from step 1 on this newly created training set. Note that to run this script one _must_ first run the `notebooks/Generate_Pseudo.ipynb` notebook, generate the pseudo-labels and set the dataframe path (`pseudo_df` variable) accordingly inside this script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc199b29-bf42-44fa-b156-674d31957f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training process could take up to 1 hour\n",
    "# This will generate pseudo_label.log and unet_pseudo_mobilenetv2_round1_{rank}.pth\n",
    "%run src/train_pseudo_label.py -p Best_IoU/unet_mobilenet_v2_0.pth -f unet_pseudo_mobilenetv2_round1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5217c7-69bc-46a7-97ed-0d6a1b43fabd",
   "metadata": {},
   "source": [
    "4. Repeat for n rounds. In our experiments, we do it for 2 rounds. \n",
    "**Note**: After the first round of pseudo-labeling, we refine our pseudo-labels. This process is again\n",
    "governed by an averaged ensemble but instead of using just two models we also add the model (trained with pseudo-labels\n",
    "in the last iteration) to the ensemble. This change is incorporated in the `notebooks/Generate_Pseudo.ipynb` notebook\n",
    "and is executed thereafter.\n",
    "\n",
    "> This idea of pseudo-label generation is taken from this talk: [How to cook pseudo-labels](https://www.youtube.com/watch?v=SsnWM1xWDu4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c468213-97ca-4f4c-bcb0-10d292340890",
   "metadata": {},
   "source": [
    "Link to the `Generate_Pseudo.ipynb` notebook is [**here**](Generate_Pseudo.ipynb). The execution of this notebook will generate a `pseudo_label` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082898c9-5535-4312-972b-a7f2d84f5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training process could take up to 1 hour\n",
    "# This will generate pseudo_label.log and unet_pseudo_mobilenetv2_round1_{rank}.pth\n",
    "%run src/train_pseudo_label.py -p Best_IoU/unet_mobilenet_v2_0.pth -f unet_pseudo_mobilenetv2_round2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8f432-7065-430a-8ee1-dd6c2582505b",
   "metadata": {},
   "source": [
    "After completing training for the final round, we do the following:\n",
    "\n",
    "* Using the `notebooks/Ensemble_Inference.ipynb` notebook, we first generate the initial predictions. We use stacking for ensembling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ba53c-92da-44a6-9e73-249145e1b2be",
   "metadata": {},
   "source": [
    "Link to the notebook is [**here**](Ensemble_Inference.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0146cf-cfaa-4071-b26b-b2aa37c99575",
   "metadata": {},
   "source": [
    "* We then apply Conditional Random Fields [4] on the predictions to enhance segmentation boundaries. This is demonstrated in the `notebooks/Apply_CRF.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08354d3-238a-44b4-8d36-ab07d9ad29e8",
   "metadata": {},
   "source": [
    "Link to the notebook is [**here**](Apply_CRF.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c565a26f-733f-4ebf-8378-47cd3f72f924",
   "metadata": {},
   "source": [
    "### Additional notes on our inference pipeline\n",
    "\n",
    "* For creating the model ensemble, we use the initially trained UNet and UNet++ models along with the _last_\n",
    "  fine-tuned UNet model from the pseudo-labeling step.\n",
    "* To further account for uncertainty and improve our predictions, we apply test-time augmentation using the [`ttach`](https://github.com/qubvel/ttach)\n",
    "library. \n",
    "  \n",
    "In case you have any difficulties understanding the overall workflow feel free to open an issue on GitHub and we will get back to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca2f23-274c-4523-b360-623ffc183cae",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Ronneberger O., Fischer P., Brox T. (2015) U-Net: Convolutional Networks for Biomedical Image Segmentation. In: Navab N., Hornegger J., Wells W., Frangi A. (eds) Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015. MICCAI 2015. Lecture Notes in Computer Science, vol 9351. Springer, Cham. https://doi.org/10.1007/978-3-319-24574-4_28\n",
    "\n",
    "[2] Zhou, Z., Siddiquee, M., Tajbakhsh, N., & Liang, J. (2018). UNet++: A Nested U-Net Architecture for Medical Image Segmentation. Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support : 4th International Workshop, DLMIA 2018, and 8th International Workshop, ML-CDS 2018, held in conjunction with MICCAI 2018, Granada, Spain, S..., 11045, 3–11. https://doi.org/10.1007/978-3-030-00889-5_1\n",
    "\n",
    "[3] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov and L. Chen, \"MobileNetV2: Inverted Residuals and Linear Bottlenecks,\" 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018, pp. 4510-4520, doi: 10.1109/CVPR.2018.00474.\n",
    "\n",
    "[4] Philipp Krähenbühl and Vladlen Koltun. 2011. Efficient inference in fully connected CRFs with Gaussian edge potentials. In <i>Proceedings of the 24th International Conference on Neural Information Processing Systems</i> (<i>NIPS'11</i>). Curran Associates Inc., Red Hook, NY, USA, 109–117.\n",
    "\n",
    "[5] Q. Xie, M. -T. Luong, E. Hovy and Q. V. Le, \"Self-Training With Noisy Student Improves ImageNet Classification,\" 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020, pp. 10684-10695, doi: 10.1109/CVPR42600.2020.01070.\n",
    "\n",
    "[6] Berthelot, David, et al. “AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation.” ArXiv:2106.04732 [Cs], June 2021. arXiv.org, http://arxiv.org/abs/2106.04732."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942be2a8-f5aa-48c1-8bd3-4972a3a581ed",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "* We are grateful to the [ML-GDE program](https://developers.google.com/programs/experts/) for providing GCP credits to support our experiments. \n",
    "* Thanks to [Charmi Chokshi](https://in.linkedin.com/in/charmichokshi), and domain experts Shubhankar Gahlot, May Casterline, Ron Hagensieker, Lucas Kruitwagen, Aranildo Rodrigues, Bertrand Le Saux, Sam Budd, Nick Leach, and, Veda Sunkara for insightful discussions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9ba1b-d51b-4470-bd31-96f829e8e3f9",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "```\n",
    "@inproceedings{paul2021flood,\n",
    "    title   = {Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised Learning},\n",
    "    author  = {Sayak Paul and Siddha Ganju},\n",
    "    year    = {2021},\n",
    "    URL = {https://arxiv.org/abs/2107.08369},\n",
    "    booktitle = {NeurIPS Tackling Climate Change with Machine Learning Workshop}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
