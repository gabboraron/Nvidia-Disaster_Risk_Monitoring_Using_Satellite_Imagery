{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses [this blog post](https://medium.com/cloud-to-street/jumpstart-your-machine-learning-satellite-competition-submission-2443b40d0a5a) as a reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mz4KCyB4Pw6Q"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import ttach as tta\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1QXI66oQ0z_"
   },
   "source": [
    "## Set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOi7wYOKQyjF",
    "outputId": "916e5607-3933-41d5-fefb-70b0a1e7814b"
   },
   "outputs": [],
   "source": [
    "# path to dataset root directory\n",
    "dset_root = '/dli/task/'\n",
    "test_dir = os.path.join(dset_root, 'test_internal')\n",
    "\n",
    "n_test_regions = len(glob(test_dir+'/*/'))\n",
    "print('Number of test temporal-regions: {}'.format(n_test_regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWNe2TxWVrQ1"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHnXysQzVtr_"
   },
   "outputs": [],
   "source": [
    "def get_test_id(path):\n",
    "    return path.split(\"_\")[0] + \"_\" + path.split(\"_\")[1]\n",
    "\n",
    "def make_im_name(id, suffix):\n",
    "    return id.split(\".\")[0] + f\"_{suffix}.png\"\n",
    "\n",
    "def s1_to_rgb(vv_image, vh_image):\n",
    "    ratio_image = np.clip(np.nan_to_num(vh_image/vv_image, 0), 0, 1)\n",
    "    rgb_image = np.stack((vv_image, vh_image, 1-ratio_image), axis=2)\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMhA2NnmQ5-G"
   },
   "source": [
    "## Create dataframe\n",
    "\n",
    "As per [the competition website](https://nasa-impact.github.io/etci2021/), the submission file needs to be generated following a particular sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://git.io/JsRTE -O test_sentinel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2oExzdPiPfR",
    "outputId": "d955d599-b1be-485c-88c0-214444e10086"
   },
   "outputs": [],
   "source": [
    "test_file_sequence = pd.read_csv(\"test_sentinel.csv\", header=None)\n",
    "test_file_sequence = test_file_sequence.values.squeeze().tolist()\n",
    "\n",
    "all_test_vv = [os.path.join(test_dir, get_test_id(id), \"tiles\", \"vv\", make_im_name(id, \"vv\")) \n",
    "                                                                for id in test_file_sequence]\n",
    "all_test_vh = [os.path.join(test_dir, get_test_id(id), \"tiles\", \"vh\", make_im_name(id, \"vh\")) \n",
    "                                                                for id in test_file_sequence]\n",
    "\n",
    "paths = {'vv_image_path': all_test_vv,\n",
    "         'vh_image_path': all_test_vh,\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(paths)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gus4cgUzdx3o"
   },
   "outputs": [],
   "source": [
    "class ETCIDataset(Dataset):\n",
    "    def __init__(self, dataframe, split, transform=None):\n",
    "        self.split = split\n",
    "        self.dataset = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = {}\n",
    "        \n",
    "        df_row = self.dataset.iloc[index]\n",
    "\n",
    "        # load vv and vh images\n",
    "        vv_image = cv2.imread(df_row['vv_image_path'], 0) / 255.0\n",
    "        vh_image = cv2.imread(df_row['vh_image_path'], 0) / 255.0\n",
    "        \n",
    "        # convert vv and ch images to rgb\n",
    "        rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            # no flood mask should be available\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "        else:\n",
    "            # load ground truth flood mask\n",
    "            flood_mask = cv2.imread(df_row['flood_label_path'], 0) / 255.0\n",
    "\n",
    "            # compute transformations\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=rgb_image, mask=flood_mask)\n",
    "                rgb_image = augmented['image']\n",
    "                flood_mask = augmented['mask']\n",
    "\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "            example['mask'] = flood_mask.astype('int64')\n",
    "\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls9VrVu1d3Ba"
   },
   "outputs": [],
   "source": [
    "test_dataset = ETCIDataset(test_df, split='test', transform=None)\n",
    "\n",
    "batch_size = 96 * torch.cuda.device_count()\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, \n",
    "                         num_workers=os.cpu_count(), pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJqfAoPNiPfS"
   },
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    fig,ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.imshow(img.permute(1,2,0).numpy())\n",
    "\n",
    "images = next(iter(test_loader))['image']\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(images[50:59], nrow=3, normalize=False)\n",
    "matplotlib_imshow(img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uc2z3thWRG5Q"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_single(model_def, weights):\n",
    "    model_def.load_state_dict(torch.load(weights))\n",
    "    model = tta.SegmentationTTAWrapper(model_def, tta.aliases.d4_transform(), merge_mode='mean') # mean yields the best results\n",
    "    model.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    final_predictions = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            # load image and mask into device memory\n",
    "            image = batch['image'].to(device)\n",
    "\n",
    "            # pass images into model\n",
    "            pred = model(image)\n",
    "\n",
    "            # add to final predictions\n",
    "            final_predictions.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    final_predictions = np.concatenate(final_predictions, axis=0)\n",
    "    \n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that here we are defining two model classes and then we are loading the pre-trained weights into them. These weights were obtained using the `src/train.py` script. You can plug in other models (and you should) here to construct your ensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_mobilenet = smp.Unet(\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=None, \n",
    "    in_channels=3,                  \n",
    "    classes=2                      \n",
    ")\n",
    "\n",
    "upp_mobilenet = smp.UnetPlusPlus(\n",
    "    encoder_name=\"mobilenet_v2\", \n",
    "    encoder_weights=None, \n",
    "    in_channels=3,                  \n",
    "    classes=2                      \n",
    ")\n",
    "\n",
    "model_defs = [unet_mobilenet, upp_mobilenet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [\"Best_IoU/unet_mobilenet_v2_0.pth\",\n",
    "              \"Best_IoU/upp_mobilenetv2_0.pth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "\n",
    "for defi, path in zip(model_defs, model_paths):\n",
    "    all_preds.append(get_predictions_single(defi, path))\n",
    "    \n",
    "all_preds = np.array(all_preds)\n",
    "all_preds = np.mean(all_preds, axis=0)\n",
    "class_preds = all_preds.argmax(axis=1).astype('uint8')\n",
    "\n",
    "save_path = 'submission.npy'\n",
    "np.save(save_path, class_preds, fix_imports=True, allow_pickle=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ECTI_Jumpstart.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
