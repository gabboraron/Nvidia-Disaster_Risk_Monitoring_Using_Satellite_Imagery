{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdW7nQ-cbIqo"
   },
   "source": [
    "## Important links\n",
    "\n",
    "* https://nasa-impact.github.io/etci2021/\n",
    "* https://competitions.codalab.org/competitions/30440"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZo0QYmDnyb7"
   },
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGjp5GS9bzNn",
    "outputId": "f1dbe379-9381-4095-931d-54882369bd6f"
   },
   "outputs": [],
   "source": [
    "!ls -lh train | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PX00Kq1YcLQh",
    "outputId": "0e0ded97-91fd-47bf-9711-43a452087aed"
   },
   "outputs": [],
   "source": [
    "!ls -lh train/bangladesh_20170314t115609/tiles | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCYM6RQ4cXlm",
    "outputId": "7cd939de-1bf0-4777-9c43-b8a42e261ab8"
   },
   "outputs": [],
   "source": [
    "!ls -lh train/bangladesh_20170314t115609/tiles/flood_label | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZva1Js7qfyO",
    "outputId": "b990c269-4eca-4d64-ff46-0512cbe6dd2b"
   },
   "outputs": [],
   "source": [
    "!ls -lh train/bangladesh_20170314t115609/tiles/vh | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpN2AOPKhKzn"
   },
   "source": [
    "From [here](https://nasa-impact.github.io/etci2021/#semantic-labels): \n",
    "\n",
    "> The provided training data is split across 29 root folders named \\<region>\\_\\<datetime>*, region being the region and datetime being the date and time of the flood event. Each root folder includes 4 sub-folders: vv, vh, water_body_label and flood_label with 2,068 files each. vv and vh correspond to the satellite images listed earlier and images in the flood_label and water_body_label folder provide reference ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICOG2m4yn1gY"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9SNgHAnhilI"
   },
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import re\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5yXXB0mn2wI"
   },
   "source": [
    "## Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-saXYh5hmMr",
    "outputId": "2898b3c0-f947-4c4d-8fbf-0aec07143e2c"
   },
   "outputs": [],
   "source": [
    "all_image_paths = list(paths.list_images(\"train\"))\n",
    "print(f\"Total images: {int(len(all_image_paths)/2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo9sYuf7iDb0"
   },
   "source": [
    "So, we have 33,406 satellite images and the rest are binary segmentation maps. \n",
    "\n",
    "For a given image id (e.g. `nebraska_20170309t002110`), its correspnding ground-truths i.e. the segmentation maps are present in either of these two folders: `water_body_label` and `flood_label`. Let's write a few utility functions for knowing the dataset in a better way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oti_hOWBmI26"
   },
   "source": [
    "**How many unique image IDs are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO4sCY85mMwV",
    "outputId": "3ca32213-f5e4-4da6-e2b7-22fa22b3ef94"
   },
   "outputs": [],
   "source": [
    "image_ids = {path.split(\"/\")[1] for path in all_image_paths}\n",
    "print(len(image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXah9TzHnILz"
   },
   "source": [
    "Now, let's investigate how are these IDs distributed? **Do all the IDs have the same amount of images present?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVGpVal5j2J0"
   },
   "outputs": [],
   "source": [
    "def get_image_paths(image_id):\n",
    "    flood_image_root = os.path.join(\"train\", image_id, \"tiles\", \"flood_label\")\n",
    "    water_body_root = os.path.join(\"train\", image_id, \"tiles\", \"water_body_label\")\n",
    "    vh_root = os.path.join(\"train\", image_id, \"tiles\", \"vh\")\n",
    "    vv_root = os.path.join(\"train\", image_id, \"tiles\", \"vv\")\n",
    "\n",
    "    flood_image_paths = list(paths.list_images(flood_image_root))\n",
    "    water_body_paths = list(paths.list_images(water_body_root))\n",
    "    vh_image_paths = list(paths.list_images(vh_root))\n",
    "    vv_image_paths = list(paths.list_images(vv_root))\n",
    "\n",
    "    return flood_image_paths, water_body_paths,\\\n",
    "        vh_image_paths, vv_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5dZk7BiimDvC",
    "outputId": "3731e75e-1b7b-461c-deb4-8afa6a1a9202"
   },
   "outputs": [],
   "source": [
    "distribution_dict = {}\n",
    "\n",
    "for id in tqdm(image_ids):\n",
    "    distribution_dict[id] = {}\n",
    "    flood_image_paths, water_body_paths, vh_image_paths, vv_image_paths = \\\n",
    "        get_image_paths(id)\n",
    "\n",
    "    distribution_dict[id][\"flood_images\"] = len(flood_image_paths)\n",
    "    distribution_dict[id][\"water_body_images\"] = len(water_body_paths)\n",
    "    distribution_dict[id][\"vh_images\"] = len(vh_image_paths)\n",
    "    distribution_dict[id][\"vv_images\"] = len(vv_image_paths)\n",
    "\n",
    "distribution_df = pd.DataFrame.from_dict(distribution_dict).T\n",
    "assert len(distribution_df) == len(image_ids)\n",
    "distribution_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7-1q6k_pmVg"
   },
   "source": [
    "No huge distribution skews noticed. But for **`bangladesh_20170314t115609`** there is a mismatch between the number of flood image maps and the number of VV images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly1feNzrw9x_"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Now, let's write a utility function that would return the images belonging to the format - `<region>_<datetime>*_x-*_y-*.png`. \n",
    "\n",
    "It seems like the VV images should be used for predicting flood levels and VH images should be used for predicting water body levels.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=https://i.ibb.co/mCZp6X4/image.png></ing>\n",
    "</p>\n",
    "\n",
    "However, \n",
    "\n",
    "> We expect participants to provide a binary segmentation of the region of interest (ROI), (i.e. 256x256 pixels) as a numpy array with the byte (uint8) data type:\n",
    "**1: Flood region, 0: Not flood region**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GGeTAT6xgEd"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/2669120/7636462\n",
    "def sorted_nicely(l): \n",
    "    convert = lambda text: int(text) if text.isdigit() else text \n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybMpR4Lr1XwU",
    "outputId": "0bf007f7-1f4d-4b38-82da-753c8ed58b66"
   },
   "outputs": [],
   "source": [
    "all_image_paths = sorted_nicely(all_image_paths)\n",
    "\n",
    "vv_image_paths = [path for path in all_image_paths if (\"vv\" in path) and (\"ipynb_checkpoints\" not in path)]\n",
    "flood_image_paths = [path for path in all_image_paths if (\"flood\" in path) and (\"ipynb_checkpoints\" not in path)]\n",
    "vh_image_paths = [path for path in all_image_paths if (\"vh\" in path) and (\"ipynb_checkpoints\" not in path)]\n",
    "water_body_label_paths = [path for path in all_image_paths if (\"water\" in path) and (\"ipynb_checkpoints\" not in path)]\n",
    "\n",
    "len(flood_image_paths), len(vv_image_paths), len(vh_image_paths), len(water_body_label_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "56YkE9eO-tV2",
    "outputId": "cf9e881c-5afb-4304-f0d8-5a6d5e3f5aaa"
   },
   "outputs": [],
   "source": [
    "all_image_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSjPRl7h_3fq"
   },
   "source": [
    "What is `.ipynb_checkpoints` doing here? ðŸ˜¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgyNRBv5-77w",
    "outputId": "ab93dfa3-5757-40ab-dbf6-5723cb505979"
   },
   "outputs": [],
   "source": [
    "# Verify if we have maintained the order\n",
    "flood_image_paths[:5], vv_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMo5X1YC-u-I",
    "outputId": "c33991ad-674b-4ce4-e2ba-5a1140c7bbb8"
   },
   "outputs": [],
   "source": [
    "water_body_label_paths[:5], vh_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWnesEnH_Myh"
   },
   "outputs": [],
   "source": [
    "def get_image_id(filename):\n",
    "    return filename.split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E594rhX5-162"
   },
   "outputs": [],
   "source": [
    "def show_all_four_images(filenames, titles):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(mpimg.imread(filename))\n",
    "        \n",
    "    plt.suptitle(get_image_id(filenames[0]), size=16)\n",
    "    columns = 4\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(len(images)/ columns + 1, columns, i + 1)\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(image)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wo1PLOaHHnTF"
   },
   "outputs": [],
   "source": [
    "regex = r\"_x-\\d+_y-\\d+\"\n",
    "compiler = re.compile(regex)\n",
    "\n",
    "def get_intensity(path):\n",
    "    return compiler.search(path).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kGZrcDtv-_0G",
    "outputId": "f900fbc2-7c6b-4ae5-b839-d0cfcb2ea45b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "titles = [\"V V\",\"V H\" , \"Land or water before flood/Water body image\" ,\"After Flood/flood image\"]\n",
    "\n",
    "random_index =  random.sample(range(0, len(vv_image_paths)), 10) \n",
    "for i in random_index:\n",
    "    # The assertions make sure we are operating on the right pairs\n",
    "    assert  get_intensity(vv_image_paths[i]) == get_intensity(flood_image_paths[i])\n",
    "    assert  get_intensity(vh_image_paths[i]) == get_intensity(water_body_label_paths[i])\n",
    "    show_all_four_images([vv_image_paths[i], vh_image_paths[i],  \n",
    "                          water_body_label_paths[i], flood_image_paths[i] ] , titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9xG2zqRMDL6"
   },
   "source": [
    "**Some noise found (from an earlier iteration)**:\n",
    "\n",
    "* https://ibb.co/m6x9f1S\n",
    "* https://ibb.co/rfWtJy7\n",
    "\n",
    "How in an all-white image, any segmentation map is present? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6auRGru_Xmy"
   },
   "source": [
    "### Displaying the RGB composite\n",
    "\n",
    "From [here](https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/product-overview/polarimetry):\n",
    "\n",
    "> The composite RGB (colour) image on the right was created using the VV channel for red, VH channel for green and the ratio $|VV| / |VH|$ for blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "em9A7OGT_cQr",
    "outputId": "5a5c6e0f-4fb3-4ed2-8440-30974886fba6"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def show_all_combined_images(i, titles):\n",
    "    columns = 3\n",
    "\n",
    "    red, _ , _  = Image.open(vv_image_paths[i]).split()\n",
    "    red = np.asarray(red)\n",
    "    _, green, _  = Image.open(vh_image_paths[i]).split()\n",
    "    green = np.asarray(green)\n",
    "\n",
    "    blue = np.abs(red) / np.abs(green) \n",
    "    blue = (blue * 255).astype(np.uint8)\n",
    "    rgb = Image.fromarray(np.dstack((red,green,blue)))\n",
    "\n",
    "    images = [rgb]\n",
    "    images.append(mpimg.imread(water_body_label_paths[i]))\n",
    "    images.append(mpimg.imread(flood_image_paths[i]))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.suptitle(get_image_id(vv_image_paths[i]), size=16)\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(len(images)/ columns + 1, columns, i + 1)\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(image)\n",
    "\n",
    "\n",
    "titles = [\"Combined\" , \"Land or water before flood/Water body image\" ,\"After Flood/flood image\"]\n",
    "for i in random_index:\n",
    "    show_all_combined_images(i , titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3m2FFZNgEoH6"
   },
   "source": [
    "## Observations\n",
    "\n",
    "* We need to be careful about the way we would shuffle the samples. We likely wouldn't want to just randomly shuffle them. Because if we do so then the continual order of samples for a particular region and timestamp would get broken. \n",
    "* We also cannot randomly sample data points for our local validation set. It's much like predicting the next frame for a given sequence of frames. We would want to train models on a sequence of *ordered* frames and use that to infer the next one. \n",
    "* Can we simply discard the blank images (all white ones under `Combined` and their respective labels)? I don't see any point in keeping them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hfNf05tMk-0"
   },
   "source": [
    "## Some preprocessing \n",
    "\n",
    "Referred from this [video](https://youtu.be/derOXkPCH80). A PDF is present [here](http://step.esa.int/docs/tutorials/S1TBX%20SAR%20Basics%20Tutorial.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-d9KEDlMxrq"
   },
   "source": [
    "### Speckle removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CsEObUJMqOc"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/39786527/7636462\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "\n",
    "def lee_filter(img, size=20):\n",
    "    img_mean = uniform_filter(img, (size, size, size))\n",
    "    img_sqr_mean = uniform_filter(img**2, (size, size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPCtW9E-PSNX"
   },
   "outputs": [],
   "source": [
    "random_index =  random.sample(range(0, len(vv_image_paths)), 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HkXQBuSVN_Vn",
    "outputId": "cf79231b-09b4-40b6-cab0-b0f550f213f0"
   },
   "outputs": [],
   "source": [
    "# With Speckle Removal\n",
    "\n",
    "def show_all_four_images(filenames, titles, speckle=False):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        image = mpimg.imread(filename)\n",
    "        if speckle:\n",
    "            lee_filter(image)\n",
    "        images.append(image)\n",
    "        \n",
    "    plt.suptitle(get_image_id(filenames[0]), size=16)\n",
    "    columns = 4\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(len(images)/ columns + 1, columns, i + 1)\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(image)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "titles = [\"V V\",\"V H\" , \"Land or water before flood/Water body image\" ,\"After Flood/flood image\"]\n",
    "\n",
    "for i in random_index:\n",
    "    show_all_four_images([vv_image_paths[i], vh_image_paths[i],  \n",
    "                          water_body_label_paths[i], flood_image_paths[i] ] , titles, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LZDu2KwYOhKa",
    "outputId": "7fdc41f0-bf4e-458a-dac5-50ed8e5892ad"
   },
   "outputs": [],
   "source": [
    "# Without Speckle\n",
    "\n",
    "for i in random_index:\n",
    "    show_all_four_images([vv_image_paths[i], vh_image_paths[i],  \n",
    "                          water_body_label_paths[i], flood_image_paths[i] ] , titles, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWZSFxwbP0ZF"
   },
   "source": [
    "Seems like the Sentinel-1 images have gone through some speckle removal already. We can confirm this by examining the distribution of the histograms. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Data_Viz.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
